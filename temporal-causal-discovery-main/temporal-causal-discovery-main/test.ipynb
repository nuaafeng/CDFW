{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics:\n",
      "loss: 1.2230085134506226\n",
      "AUROC: 0.5555555820465088\n",
      "\n",
      "Artifacts:\n",
      "prediction: torch.Size([3, 14])\n",
      "attention_logits: torch.Size([3, 3])\n",
      "matrix: torch.Size([3, 3])\n",
      "TPR: torch.Size([9])\n",
      "FPR: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from src.models.TCN import TCN\n",
    "from src.eval.soft_auroc import AUROC\n",
    "from src.utils import min_max_normalization\n",
    "\n",
    "\n",
    "class TAMCaD(nn.Module):\n",
    "    def __init__(self, n_variables, hidden_dim, gamma, dropout, **kwargs):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma  # continuous matrices\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.tcn = TCN(\n",
    "                in_channels=n_variables,\n",
    "                out_channels=n_variables * hidden_dim,\n",
    "                hidden_dim=n_variables * hidden_dim,\n",
    "                groups=n_variables,\n",
    "                dropout=dropout,\n",
    "                **kwargs\n",
    "            )\n",
    "        self.attention_logits = nn.Parameter(0.2 + 0.1 * torch.randn(n_variables, n_variables))\n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=n_variables * hidden_dim,\n",
    "                      out_channels=n_variables * (hidden_dim // 2),\n",
    "                      kernel_size=1, groups=n_variables),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(in_channels=n_variables * (hidden_dim // 2),\n",
    "                      out_channels=n_variables,\n",
    "                      kernel_size=1, groups=n_variables)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_noise_adjusted=None, create_artifacts=False,\n",
    "                temporal_matrix=False, ground_truth=None, mask=None):\n",
    "\n",
    "        batch_size, n_var, seq_len = x.size()\n",
    "\n",
    "        context = self.tcn(x).reshape(batch_size, n_var, self.hidden_dim, -1)\n",
    "\n",
    "        # Apply masking if provided\n",
    "        if self.training:\n",
    "            tau = 0.7  # Temperature parameter, adjust this according to your needs\n",
    "            gumbels = -torch.log(-torch.log(torch.rand_like(self.attention_logits) + 1e-20) + 1e-20)  # Sample from Gumbel(0, 1)\n",
    "            attentions = torch.softmax((self.attention_logits + gumbels) / tau, dim=-1)  # Apply softmax\n",
    "        else:\n",
    "            attentions = torch.softmax(self.attention_logits, dim=-1)\n",
    "\n",
    "        # x: (batch_size, n_var * hidden_dim, sequence_length)\n",
    "        z = torch.einsum('ij, bjdt -> bidt', attentions, context).reshape(batch_size, n_var * self.hidden_dim, -1)\n",
    "\n",
    "        prediction = self.prediction(z)\n",
    "\n",
    "        return self.process(x, prediction, self.attention_logits, x_noise_adjusted,\n",
    "                            create_artifacts, ground_truth, attentions)\n",
    "\n",
    "    def process(self, x, prediction, attention_logits, x_noise_adjusted,\n",
    "                create_artifacts, ground_truth, attentions):\n",
    "        \"\"\"\n",
    "        Processes the outputs of the forward pass, computing losses and other metrics.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): Original input tensor of size (batch_size, n_var, seq_len).\n",
    "            prediction (torch.Tensor): Prediction tensor from the model\n",
    "                of size (batch_size, n_var, seq_len).\n",
    "            attention_logits (torch.Tensor): attention_logits tensor from the model\n",
    "                of size (batch_size, n_var, n_var, seq_len).\n",
    "            x_noise_adjusted (torch.Tensor, optional): Tensor of true mean values of the time series\n",
    "                of size (batch_size, n_var, seq_len).\n",
    "            create_artifacts (bool): Flag indicating whether to return artifacts.\n",
    "            temporal_matrix (bool): Flag to use sliding window for temporal matrices.\n",
    "            ground_truth (torch.Tensor, optional): Ground truth tensor for the causal matrix an is\n",
    "                of size (n_var, n_var) or (n_var, n_var, seq_len), corresponding with temporal_matrix flag.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the loss, prediction, and optional metrics like causal matrix and AUROC.\n",
    "        \"\"\"\n",
    "        metrics, artifacts = {}, {}\n",
    "        s = prediction.size(-1) - 1\n",
    "        #assert False, (x.shape, prediction.shape)\n",
    "        loss = nn.functional.mse_loss(x[..., -s:], prediction[..., :-1])\n",
    "        prediction = prediction.detach()  # (1, n_var, seq_len)\n",
    "\n",
    "        attention_logits = attention_logits.detach()  # (bs, n_var, n_var, seq_len)\n",
    "        if self.gamma > 0:\n",
    "            #loss = loss + self.gamma * torch.diff(attention_logits, dim=-1).abs().mean()\n",
    "            loss = loss + self.gamma * attentions.pow(0.1).mean()\n",
    "\n",
    "        metrics['loss'] = loss\n",
    "        if create_artifacts:\n",
    "            artifacts = {\n",
    "                'prediction': prediction.squeeze(0),\n",
    "                'attention_logits': attention_logits\n",
    "            }\n",
    "\n",
    "        # Additional computations if noise-adjusted values are provided\n",
    "        if x_noise_adjusted is not None:\n",
    "            metrics['noise_adjusted_regression_loss'] = nn.functional.mse_loss(x_noise_adjusted[..., 1 - s:],\n",
    "                                                                               prediction[..., :-1])\n",
    "\n",
    "        # Compute causal matrix and AUROC if needed\n",
    "        if create_artifacts or ground_truth is not None:\n",
    "            causal_matrix = attention_logits\n",
    "\n",
    "            if create_artifacts:\n",
    "                artifacts['matrix'] = min_max_normalization(causal_matrix, min_val=0.0, max_val=1.0)\n",
    "\n",
    "            if ground_truth is not None:\n",
    "                ground_truth = ground_truth.to(causal_matrix.device)\n",
    "\n",
    "                auc, tpr, fpr = AUROC(ground_truth, causal_matrix)\n",
    "                metrics.update({'AUROC': auc})\n",
    "                if create_artifacts:\n",
    "                    artifacts.update({'TPR': tpr, 'FPR': fpr})\n",
    "\n",
    "        return metrics, artifacts\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Parameters for the model\n",
    "    n_variables = 3\n",
    "    hidden_dim = 16\n",
    "    lambda1, beta, gamma = 0.1, 0.1, 0.1\n",
    "    tcn_params = {'n_blocks': 2, 'n_layers': 2, 'kernel_size': 2, 'dropout': 0.2}\n",
    "\n",
    "    # Initialize the NAVAR model\n",
    "    model = TAMCaD(n_variables, hidden_dim, gamma, **tcn_params)\n",
    "\n",
    "    # Generate dummy input data (batch_size, n_variables, sequence_length)\n",
    "    batch_size = 1\n",
    "    sequence_length = 20\n",
    "    x = torch.randn(batch_size, n_variables, sequence_length)\n",
    "\n",
    "    # Run the model\n",
    "    metrics, artifacts = model.forward(x,\n",
    "                                       create_artifacts=True,\n",
    "                                       ground_truth=torch.randn(n_variables, n_variables) > 0,\n",
    "                                       temporal_matrix=False)\n",
    "\n",
    "    # Print the results\n",
    "    print('Metrics:')\n",
    "    for k in metrics.keys():\n",
    "        print(f\"{k}:\", metrics[k].item() if metrics[k].numel() == 1 else metrics[k].shape)\n",
    "    if len(artifacts) > 0:\n",
    "        print('\\nArtifacts:')\n",
    "        for k in artifacts.keys():\n",
    "            print(f\"{k}:\", artifacts[k].item() if artifacts[k].numel() == 1 else artifacts[k].shape)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
